# -*- coding: utf-8 -*-
"""Autoinland.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iNHA-1of9tseNCK1pxn358NTyJyC17cK

# Set up
"""

pip install catboost

!pip install --upgrade fastcore -q
!pip install --upgrade fastai -q

from fastai.vision.all import * # Needs latest version, and sometimes a restart of the runtime after the pip installs

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
np.random.seed(123)
warnings.filterwarnings('ignore')
# %matplotlib inline

tr = pd.read_csv('Train (4).csv')

tr.shape

tr.head()

ts = pd.read_csv('Test (4).csv')

ts.shape

ts.head()

vdef = pd.read_csv('VariableDefinitions (2).csv')
vdef

"""# Data Understanding"""

tr.dtypes

ts.dtypes

tr.isna().sum()

# Visualize the missing values in train set
ax = tr.isna().sum().sort_values().plot(kind = 'barh', figsize = (9, 10))
plt.title('Percentage of Missing Values Per Column in Train Set', fontdict={'size':15})
for p in ax.patches:
    percentage ='{:,.0f}%'.format((p.get_width()/tr.shape[0])*100)
    width, height =p.get_width(),p.get_height()
    x=p.get_x()+width+0.02
    y=p.get_y()+height/2
    ax.annotate(percentage,(x,y))

ts.isna().sum()

# Visualize the missing values in test set
ax = ts.isna().sum().sort_values().plot(kind = 'barh', figsize = (9, 10))
plt.title('Percentage of Missing Values Per Column in Test Set', fontdict={'size':15})
for p in ax.patches:
    percentage ='{:,.0f}%'.format((p.get_width()/tr.shape[0])*100)
    width, height =p.get_width(),p.get_height()
    x=p.get_x()+width+0.02
    y=p.get_y()+height/2
    ax.annotate(percentage,(x,y))

#unique elements in our data:
cols = tr.columns.to_list()

for col in cols:
  print('COLUMN:', col)
  print('Number of unique variables:', tr[col].nunique())
  print(tr[col].unique())
  print()

tr.duplicated().any()

ts.duplicated().any()

"""# Data Cleaning

From here we'll work with a combination of the train and test to speed things up
"""

# Combine train and test set
ntr = tr.shape[0] # to be used to split train and test set from the combined dataframe

all_data = pd.concat((tr, ts)).reset_index(drop=True)
print(f'The shape of the combined dataframe is: {all_data.shape}')

all_data.head()

#Checking outliers:
all_data.boxplot(column =['Age'])

"""The many outliers on the age variable could suggest:


*   An issue with data entry
*   Clients not understanding the question


"""



#viewing the outliers in age(less than 14)
outlie1 = all_data[all_data['Age']<14]
outlie1_cnt = outlie1['ID'].groupby(outlie1['Age']).count()
outlie1_cnt

"""The age column has many outliers and would require more processing; hence there could be many ways of handling it. For the project several methods will be tried out and their perfomance rated against each other:"""

# 1: Dropping the Age column:
all_data = all_data.drop(['Age'], axis=1)

others = all_data[['No_Pol']]
others.boxplot()

"""Gender Column:"""

mapper = {'Entity':'Other', 'Joint Gender':'Other', 'NOT STATED':'Other', 'NO GENDER': 'Other', 'SEX':"Other"}
all_data.Gender = all_data.Gender.replace(mapper)

# Confirm mappings
all_data.Gender.value_counts()

#filling NA in gender with 'other'
all_data['Gender'] = all_data['LGA_Name'].fillna('Other')

"""Missing Values:
Missing values in the remaining columns will be filled with the mode value. So first we need to output the 1st five in each column:
"""

mode_color = all_data['ID'].groupby(all_data['Subject_Car_Colour']).count().sort_values(ascending=False)[:5]
mode_color

mode_LGA =all_data['ID'].groupby(all_data['LGA_Name']).count().sort_values(ascending=False)[:5]
mode_LGA

mode_state = all_data['ID'].groupby(all_data['State']).count().sort_values(ascending=False)[:5]
mode_state

mode_cat = all_data['ID'].groupby(all_data['Car_Category']).count().sort_values(ascending=False)[:5]
mode_cat

mode_make = all_data['ID'].groupby(all_data['Subject_Car_Make']).count().sort_values(ascending=False)[:5]
mode_make

#performing the filling:
all_data['Subject_Car_Colour'] = all_data['Subject_Car_Colour'].fillna('Black')
all_data['LGA_Name'] = all_data['LGA_Name'].fillna('Victoria Island')
all_data['State'] = all_data['State'].fillna('Lagos')
all_data['Car_Category'] = all_data['Car_Category'].fillna('Saloon')
all_data['Subject_Car_Make'] = all_data['Subject_Car_Make'].fillna('TOYOTA')

all_data.isna().any()

"""# Data Preparation"""

all_data['target'] = all_data['target'].astype('float64')

# LabelBinarizer converts the string categorical variable to binary 
from sklearn.preprocessing import LabelBinarizer
lb= LabelBinarizer()
all_data['target']= lb.fit_transform(['target'])

sns.countplot('target', data = all_data);

# DATA TYPES:
cat_cols = ['Gender','Car_Category', 'Subject_Car_Colour', 'Subject_Car_Make', 'LGA_Name', 'State', 'ProductName']
num_cols = ['No_Pol']
date_cols = date_cols = [col for col in all_data.columns if 'Date' in col]

# Change columns to their respective datatypes
all_data[cat_cols] = all_data[cat_cols].astype('category')

# Confirm whether the changes have been successful
all_data.info()

# Use one hot encoding to turn categorical features to numerical features
# Encode categorical features
all_data = pd.get_dummies(data = all_data, columns = cat_cols)
all_data.head()

# Separate train and test data from the combined dataframe
train = all_data[:ntr]
test = all_data[ntr:]

# Check the shapes of the split dataset
train.shape, test.shape

"""# Model"""

date_cols = [col for col in all_data.columns if 'Date' in col]
# Select main columns to be used in training
main_cols = all_data.columns.difference(date_cols+['ID', 'target'])
X = train[main_cols]
y = train.target

X.head()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42, stratify=y)

#import classifier algorithm 
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import ExtraTreesClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# create models
lg_model = LogisticRegression()
rf_model = RandomForestClassifier()
kn_model = KNeighborsClassifier()
et_model = ExtraTreesClassifier()
xg_model = XGBClassifier()
lgbm_model = LGBMClassifier()

#training the models
lg_model.fit(X_train,y_train)
rf_model.fit(X_train,y_train)
kn_model.fit(X_train,y_train)
et_model.fit(X_train,y_train)
xg_model.fit(X_train,y_train)
lgbm_model.fit(X_train, y_train)

#making predictions
lg_y_pred = lg_model.predict(X_test)
rf_y_pred = rf_model.predict(X_test)
kn_y_pred = kn_model.predict(X_test)
et_y_pred = et_model.predict(X_test)
xg_y_pred = xg_model.predict(X_test)
lgbm_y_pred = lgbm_model.predict(X_test)

# importing our machine learning algorithms  
from sklearn.tree import DecisionTreeClassifier 
from sklearn.ensemble import GradientBoostingClassifier

# create models
dst_model = DecisionTreeClassifier()
gbm_model = GradientBoostingClassifier()

#training the models
dst_model.fit(X_train,y_train)
gbm_model.fit(X_train,y_train)

#making predictions
dst_y_pred = dst_model.predict(X_test)
gbm_y_pred = gbm_model.predict(X_test)

dst_y_pred

y_test

"""## Model Evaluation"""

# import evaluation metrics
from sklearn.metrics import f1_score

# evaluate the model
# roc_auc_score
# Check the f1 score of the model
#print(f'F1 score on the X_test is: {f1_score(y_test, y_pred)}')
print(f"Logistic Regression classifier: ", f1_score(y_test, lg_y_pred))
print("Random Forest classifier: ", f1_score(y_test, rf_y_pred))
print("KNeighbors Classifier: ", f1_score(y_test, kn_y_pred))
print("Extra Tree classifier: ", f1_score(y_test, et_y_pred))
print("XGB classifier: ", f1_score(y_test, xg_y_pred))
print('LGBM AUC score on the X_test is:', f1_score(y_test, lgbm_y_pred))
print("DecisionTreeClassifier : ", f1_score(y_test, dst_y_pred))
print("GradientBoostingClassifier: ", f1_score(y_test, gbm_y_pred))

"""## Making model better"""

from sklearn.model_selection import GridSearchCV

# Optimize model paramaters 
param_grid = {'min_child_weight': [1, 5, 10],
        'gamma': [0, 1],
        'subsample': [0.6, 0.8, 1.0],
        'max_depth': [3,5]
        }
my_xg_model = GridSearchCV(xg_model, param_grid,n_jobs=-1,verbose=2,cv=5)
my_xg_model.fit(X_train, y_train)
print(my_xg_model.best_params_)

from sklearn.metrics import confusion_matrix, accuracy_score

# fit by setting best parameters and Evaluate model
xgb_model = XGBClassifier(min_child_weight=5, gamma=0.5, subsample=0.6, max_depth=3)

xgb_model.fit(X_train, y_train)
y_pred = xgb_model.predict_proba(X_test)[:, 1]

# Get error rate
print("New XGB classifier: ", roc_auc_score(y_test, y_pred))

"""### CATBST"""

from catboost import CatBoostClassifier

clf = CatBoostClassifier(
    iterations=5, 
    learning_rate=0.1, 
    #loss_function='CrossEntropy'
)


clf.fit(X_train, y_train, 
        #cat_features = cat_features, 
        eval_set=(X_test, y_test), 
        verbose=False
)

print('CatBoost model is fitted: ' + str(clf.is_fitted()))
print('CatBoost model parameters:')
print(clf.get_params())

from catboost import CatBoostClassifier
clf = CatBoostClassifier(
    iterations=5,
#     verbose=5,
)

clf.fit(
    X_train, y_train,
    #cat_features=cat_features,
    eval_set=(X_test, y_test),
)

print(clf.predict(data=X_test))

from catboost import CatBoostClassifier

clf = CatBoostClassifier(
    iterations=54,
    random_seed=42,
    learning_rate=0.6,
    custom_loss=['AUC', 'Accuracy']
)

clf.fit(
    X_train, y_train,
    # cat_features=cat_features,
    eval_set=(X_test, y_test),
    verbose=False,
    plot=True
)

"""# Submission"""

X_train[:4]

test = test[main_cols]
test[:4]

# Get the predicted result for the test Data with the model of choice
prediction = clf.predict(test)

prediction

"""Making Submission:"""

ss = pd.read_csv('SampleSubmission (4).csv')
ss[:5]

# Create a submission file
sub_file = ss.copy()
sub_file.target = prediction

sub_file.to_csv('clf.csv', index = False)
sub_file.head()